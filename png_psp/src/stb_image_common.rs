// Generated by Hebron at 1/1/2022 6:43:55 AM

use crate::{*, stb_image_png::*};
use c_runtime;
use psp::panic;

pub const SCAN_header: i32 = 2;

pub const SCAN_load: i32 = 0;

pub const SCAN_type: i32 = 1;

pub const STBI_default: i32 = 0;

pub const STBI_grey: i32 = 1;

pub const STBI_grey_alpha: i32 = 2;

pub const STBI_ORDER_BGR: i32 = 1;

pub const STBI_ORDER_RGB: i32 = 0;

pub const STBI_rgb: i32 = 3;

pub const STBI_rgb_alpha: i32 = 4;

pub static mut first_row_filter: [u8; 5] = [
    ((F_none) as u8),
    ((F_sub) as u8),
    ((F_none) as u8),
    ((F_avg_first) as u8),
    ((F_paeth_first) as u8),
];
pub static mut bmask: [u32; 17] = [
    ((0) as u32),
    ((1) as u32),
    ((3) as u32),
    ((7) as u32),
    ((15) as u32),
    ((31) as u32),
    ((63) as u32),
    ((127) as u32),
    ((255) as u32),
    ((511) as u32),
    ((1023) as u32),
    ((2047) as u32),
    ((4095) as u32),
    ((8191) as u32),
    ((16383) as u32),
    ((32767) as u32),
    ((65535) as u32),
];
pub static mut de_iphone_flag_global: i32 = 0;
pub static mut de_iphone_flag_local: i32 = 0;
pub static mut de_iphone_flag_set: i32 = 0;
pub static mut depth_scale_table: [u8; 9] = [
    ((0) as u8),
    ((0xff) as u8),
    ((0x55) as u8),
    ((0) as u8),
    ((0x11) as u8),
    ((0) as u8),
    ((0) as u8),
    ((0) as u8),
    ((0x01) as u8),
];
pub static mut h2l_gamma_i: f32 = 1.0f32 / 2.2f32;
pub static mut h2l_scale_i: f32 = 1.0f32;
pub static mut jbias: [i32; 16] = [
    0, -1, -3, -7, -15, -31, -63, -127, -255, -511, -1023, -2047, -4095, -8191, -16383, -32767,
];
pub static mut jpeg_dezigzag: [u8; 79] = [
    ((0) as u8),
    ((1) as u8),
    ((8) as u8),
    ((16) as u8),
    ((9) as u8),
    ((2) as u8),
    ((3) as u8),
    ((10) as u8),
    ((17) as u8),
    ((24) as u8),
    ((32) as u8),
    ((25) as u8),
    ((18) as u8),
    ((11) as u8),
    ((4) as u8),
    ((5) as u8),
    ((12) as u8),
    ((19) as u8),
    ((26) as u8),
    ((33) as u8),
    ((40) as u8),
    ((48) as u8),
    ((41) as u8),
    ((34) as u8),
    ((27) as u8),
    ((20) as u8),
    ((13) as u8),
    ((6) as u8),
    ((7) as u8),
    ((14) as u8),
    ((21) as u8),
    ((28) as u8),
    ((35) as u8),
    ((42) as u8),
    ((49) as u8),
    ((56) as u8),
    ((57) as u8),
    ((50) as u8),
    ((43) as u8),
    ((36) as u8),
    ((29) as u8),
    ((22) as u8),
    ((15) as u8),
    ((23) as u8),
    ((30) as u8),
    ((37) as u8),
    ((44) as u8),
    ((51) as u8),
    ((58) as u8),
    ((59) as u8),
    ((52) as u8),
    ((45) as u8),
    ((38) as u8),
    ((31) as u8),
    ((39) as u8),
    ((46) as u8),
    ((53) as u8),
    ((60) as u8),
    ((61) as u8),
    ((54) as u8),
    ((47) as u8),
    ((55) as u8),
    ((62) as u8),
    ((63) as u8),
    ((63) as u8),
    ((63) as u8),
    ((63) as u8),
    ((63) as u8),
    ((63) as u8),
    ((63) as u8),
    ((63) as u8),
    ((63) as u8),
    ((63) as u8),
    ((63) as u8),
    ((63) as u8),
    ((63) as u8),
    ((63) as u8),
    ((63) as u8),
    ((63) as u8),
];
pub static mut l2h_gamma: f32 = 2.2f32;
pub static mut l2h_scale: f32 = 1.0f32;
pub static mut unpremultiply_on_load_global: i32 = 0;
pub static mut unpremultiply_on_load_local: i32 = 0;
pub static mut unpremultiply_on_load_set: i32 = 0;
pub static mut vertically_flip_on_load_global: i32 = 0;
pub static mut vertically_flip_on_load_local: i32 = 0;
pub static mut vertically_flip_on_load_set: i32 = 0;
pub static mut zdefault_distance: [u8; 32] = [
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
    ((5) as u8),
];
pub static mut zdefault_length: [u8; 288] = [
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((9) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((7) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
    ((8) as u8),
];
pub static mut zdist_base: [i32; 32] = [
    1, 2, 3, 4, 5, 7, 9, 13, 17, 25, 33, 49, 65, 97, 129, 193, 257, 385, 513, 769, 1025, 1537,
    2049, 3073, 4097, 6145, 8193, 12289, 16385, 24577, 0, 0,
];
pub static mut zdist_extra: [i32; 30] = [
    0, 0, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13,
    13,
];
pub static mut zlength_base: [i32; 31] = [
    3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 19, 23, 27, 31, 35, 43, 51, 59, 67, 83, 99, 115, 131,
    163, 195, 227, 258, 0, 0,
];
pub static mut zlength_extra: [i32; 31] = [
    0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 0, 0, 0,
];
pub static mut compute_huffman_codes_length_dezigzag: [u8; 19] = [
    ((16) as u8),
    ((17) as u8),
    ((18) as u8),
    ((0) as u8),
    ((8) as u8),
    ((7) as u8),
    ((9) as u8),
    ((6) as u8),
    ((10) as u8),
    ((5) as u8),
    ((11) as u8),
    ((4) as u8),
    ((12) as u8),
    ((3) as u8),
    ((13) as u8),
    ((2) as u8),
    ((14) as u8),
    ((1) as u8),
    ((15) as u8),
];
pub static mut parse_png_file_invalid_chunk: [i8; 25] = [0; 25];
pub static mut process_frame_header_rgb: [u8; 3] = [((82) as u8), ((71) as u8), ((66) as u8)];
pub static mut process_marker_tag: [u8; 6] = [
    ((65) as u8),
    ((100) as u8),
    ((111) as u8),
    ((98) as u8),
    ((101) as u8),
    ((0) as u8),
];
pub static mut shiftsigned_mul_table: [u32; 9] = [
    ((0) as u32),
    ((0xff) as u32),
    ((0x55) as u32),
    ((0x49) as u32),
    ((0x11) as u32),
    ((0x21) as u32),
    ((0x41) as u32),
    ((0x81) as u32),
    ((0x01) as u32),
];
pub static mut shiftsigned_shift_table: [u32; 9] = [
    ((0) as u32),
    ((0) as u32),
    ((0) as u32),
    ((1) as u32),
    ((0) as u32),
    ((2) as u32),
    ((4) as u32),
    ((6) as u32),
    ((0) as u32),
];

#[derive(Debug, Copy, Clone)]
pub struct context {
    pub img_x: u32,
    pub img_y: u32,
    pub img_n: i32,
    pub img_out_n: i32,
    pub io: stbi_io_callbacks,
    pub io_user_data: *mut u8,
    pub read_from_callbacks: i32,
    pub buflen: i32,
    pub buffer_start: [u8; 128],
    pub callback_already_read: i32,
    pub img_buffer: *const u8,
    pub img_buffer_end: *const u8,
    pub img_buffer_original: *const u8,
    pub img_buffer_original_end: *const u8,
}

#[derive(Debug, Copy, Clone)]
pub struct result_info {
    pub bits_per_channel: i32,
    pub num_channels: i32,
    pub channel_order: i32,
}

#[derive(Debug, Copy, Clone)]
pub struct stbi_io_callbacks {
    pub read: *mut fn(arg0: *mut u8, arg1: *mut i8, arg2: i32) -> i32,
    pub skip: *mut fn(arg0: *mut u8, arg1: i32),
    pub eof: *mut fn(arg0: *mut u8) -> i32,
}

impl core::default::Default for context {
    fn default() -> Self {
        context {
            img_x: 0,
            img_y: 0,
            img_n: 0,
            img_out_n: 0,
            io: stbi_io_callbacks::default(),
            io_user_data: core::ptr::null_mut(),
            read_from_callbacks: 0,
            buflen: 0,
            buffer_start: [0; 128],
            callback_already_read: 0,
            img_buffer: core::ptr::null_mut(),
            img_buffer_end: core::ptr::null_mut(),
            img_buffer_original: core::ptr::null_mut(),
            img_buffer_original_end: core::ptr::null_mut(),
        }
    }
}

impl core::default::Default for result_info {
    fn default() -> Self {
        result_info {
            bits_per_channel: 0,
            num_channels: 0,
            channel_order: 0,
        }
    }
}

impl core::default::Default for stbi_io_callbacks {
    fn default() -> Self {
        stbi_io_callbacks {
            read: core::ptr::null_mut(),
            skip: core::ptr::null_mut(),
            eof: core::ptr::null_mut(),
        }
    }
}

pub unsafe fn addsizes_valid(mut a: i32, mut b: i32) -> i32 {
    if b < 0 {
        return ((0) as i32);
    }
    return ((if a <= 2147483647 - b { 1 } else { 0 }) as i32);
}

pub unsafe fn at_eof(mut s: *mut context) -> i32 {
    if ((*s).io.read) != core::ptr::null_mut() {
        if (*(*s).io.eof)((*s).io_user_data) == 0 {
            return ((0) as i32);
        }
        if (*s).read_from_callbacks == 0 {
            return ((1) as i32);
        }
    }
    return ((if (*s).img_buffer >= (*s).img_buffer_end {
        1
    } else {
        0
    }) as i32);
}

pub unsafe fn bit_reverse(mut v: i32, mut bits: i32) -> i32 {
    return ((bitreverse16(v) >> (16 - bits)) as i32);
}

pub unsafe fn bitcount(mut a: u32) -> i32 {
    a = ((a & ((0x55555555) as u32)) + ((a >> 1) & ((0x55555555) as u32)));
    a = ((a & ((0x33333333) as u32)) + ((a >> 2) & ((0x33333333) as u32)));
    a = ((a + (a >> 4)) & ((0x0f0f0f0f) as u32));
    a = ((a + (a >> 8)) as u32);
    a = ((a + (a >> 16)) as u32);
    return ((a & ((0xff) as u32)) as i32);
}

pub unsafe fn bitreverse16(mut n: i32) -> i32 {
    n = ((((n & 0xAAAA) >> 1) | ((n & 0x5555) << 1)) as i32);
    n = ((((n & 0xCCCC) >> 2) | ((n & 0x3333) << 2)) as i32);
    n = ((((n & 0xF0F0) >> 4) | ((n & 0x0F0F) << 4)) as i32);
    n = ((((n & 0xFF00) >> 8) | ((n & 0x00FF) << 8)) as i32);
    return ((n) as i32);
}

pub unsafe fn blinn_8x8(mut x: u8, mut y: u8) -> u8 {
    let mut t: u32 = ((((x) as i32) * ((y) as i32) + 128) as u32);
    return (((t + (t >> 8)) >> 8) as u8);
}

pub unsafe fn clamp(mut x: i32) -> u8 {
    if ((x) as u32) > ((255) as u32) {
        if x < 0 {
            return ((0) as u8);
        }
        if x > 255 {
            return ((255) as u8);
        }
    }
    return ((x) as u8);
}

pub unsafe fn compute_y(mut r: i32, mut g: i32, mut b: i32) -> u8 {
    return ((((r * 77) + (g * 150) + (29 * b)) >> 8) as u8);
}

pub unsafe fn compute_y_16(mut r: i32, mut g: i32, mut b: i32) -> u16 {
    return ((((r * 77) + (g * 150) + (29 * b)) >> 8) as u16);
}

pub unsafe fn convert_16_to_8(
    mut orig: *mut u16,
    mut w: i32,
    mut h: i32,
    mut channels: i32,
) -> *mut u8 {
    let mut i: i32 = 0;
    let mut img_len: i32 = w * h * channels;
    let mut reduced: *mut u8 = core::ptr::null_mut();
    reduced = malloc(((img_len) as u64));
    if reduced == core::ptr::null_mut() {
        return (((if (err("outofmem")) != 0 {
            (0)
        } else {
            (0)
        }) as u64) as *mut u8);
    }
    i = ((0) as i32);
    while (i < img_len) {
        *reduced.offset((i) as isize) =
            (((((*orig.offset((i) as isize)) as i32) >> 8) & 0xFF) as u8);
        c_runtime::pre_inc(&mut i);
    }
    c_runtime::free(((orig) as *mut u8));
    return reduced;
}

pub unsafe fn convert_8_to_16(
    mut orig: *mut u8,
    mut w: i32,
    mut h: i32,
    mut channels: i32,
) -> *mut u16 {
    let mut i: i32 = 0;
    let mut img_len: i32 = w * h * channels;
    let mut enlarged: *mut u16 = core::ptr::null_mut();
    enlarged = ((malloc(((img_len * 2) as u64))) as *mut u16);
    if enlarged == core::ptr::null_mut() {
        return ((((if (err("outofmem")) != 0 {
            (0)
        } else {
            (0)
        }) as u64) as *mut u8) as *mut u16);
    }
    i = ((0) as i32);
    while (i < img_len) {
        *enlarged.offset((i) as isize) = (((((*orig.offset((i) as isize)) as i32) << 8)
            + ((*orig.offset((i) as isize)) as i32))
            as u16);
        c_runtime::pre_inc(&mut i);
    }
    c_runtime::free(orig);
    return enlarged;
}

pub unsafe fn convert_format(
    mut data: *mut u8,
    mut img_n: i32,
    mut req_comp: i32,
    mut x: u32,
    mut y: u32,
) -> *mut u8 {
    let mut i: i32 = 0;
    let mut j: i32 = 0;
    let mut good: *mut u8 = core::ptr::null_mut();
    if req_comp == img_n {
        return data;
    }

    good = malloc_mad3(req_comp, ((x) as i32), ((y) as i32), 0);
    if good == core::ptr::null_mut() {
        c_runtime::free(data);
        return (((if (err("outofmem")) != 0 {
            (0)
        } else {
            (0)
        }) as u64) as *mut u8);
    }
    j = ((0) as i32);
    while (j < ((y) as i32)) {
        let mut src: *mut u8 = (data).offset((((j) as u32) * x * ((img_n) as u32)) as isize);
        let mut dest: *mut u8 = (good).offset((((j) as u32) * x * ((req_comp) as u32)) as isize);
        {
            if ((img_n) * 8 + (req_comp)) == ((1) * 8 + (2)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    *dest.offset((0) as isize) = ((*src.offset((0) as isize)) as u8);
                    *dest.offset((1) as isize) = ((255) as u8);
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((1) as isize);
                    dest = dest.offset((2) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((1) * 8 + (3)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    let hebron_tmp1 = *src.offset((0) as isize);
                    *dest.offset((0) as isize) = hebron_tmp1;
                    *dest.offset((1) as isize) = hebron_tmp1;
                    *dest.offset((2) as isize) = hebron_tmp1;
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((1) as isize);
                    dest = dest.offset((3) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((1) * 8 + (4)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    let hebron_tmp3 = *src.offset((0) as isize);
                    *dest.offset((0) as isize) = hebron_tmp3;
                    *dest.offset((1) as isize) = hebron_tmp3;
                    *dest.offset((2) as isize) = hebron_tmp3;
                    *dest.offset((3) as isize) = ((255) as u8);
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((1) as isize);
                    dest = dest.offset((4) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((2) * 8 + (1)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    *dest.offset((0) as isize) = ((*src.offset((0) as isize)) as u8);
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((2) as isize);
                    dest = dest.offset((1) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((2) * 8 + (3)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    let hebron_tmp5 = *src.offset((0) as isize);
                    *dest.offset((0) as isize) = hebron_tmp5;
                    *dest.offset((1) as isize) = hebron_tmp5;
                    *dest.offset((2) as isize) = hebron_tmp5;
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((2) as isize);
                    dest = dest.offset((3) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((2) * 8 + (4)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    let hebron_tmp7 = *src.offset((0) as isize);
                    *dest.offset((0) as isize) = hebron_tmp7;
                    *dest.offset((1) as isize) = hebron_tmp7;
                    *dest.offset((2) as isize) = hebron_tmp7;
                    *dest.offset((3) as isize) = ((*src.offset((1) as isize)) as u8);
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((2) as isize);
                    dest = dest.offset((4) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((3) * 8 + (4)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    *dest.offset((0) as isize) = ((*src.offset((0) as isize)) as u8);
                    *dest.offset((1) as isize) = ((*src.offset((1) as isize)) as u8);
                    *dest.offset((2) as isize) = ((*src.offset((2) as isize)) as u8);
                    *dest.offset((3) as isize) = ((255) as u8);
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((3) as isize);
                    dest = dest.offset((4) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((3) * 8 + (1)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    *dest.offset((0) as isize) = ((compute_y(
                        ((*src.offset((0) as isize)) as i32),
                        ((*src.offset((1) as isize)) as i32),
                        ((*src.offset((2) as isize)) as i32),
                    )) as u8);
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((3) as isize);
                    dest = dest.offset((1) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((3) * 8 + (2)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    *dest.offset((0) as isize) = ((compute_y(
                        ((*src.offset((0) as isize)) as i32),
                        ((*src.offset((1) as isize)) as i32),
                        ((*src.offset((2) as isize)) as i32),
                    )) as u8);
                    *dest.offset((1) as isize) = ((255) as u8);
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((3) as isize);
                    dest = dest.offset((2) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((4) * 8 + (1)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    *dest.offset((0) as isize) = ((compute_y(
                        ((*src.offset((0) as isize)) as i32),
                        ((*src.offset((1) as isize)) as i32),
                        ((*src.offset((2) as isize)) as i32),
                    )) as u8);
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((4) as isize);
                    dest = dest.offset((1) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((4) * 8 + (2)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    *dest.offset((0) as isize) = ((compute_y(
                        ((*src.offset((0) as isize)) as i32),
                        ((*src.offset((1) as isize)) as i32),
                        ((*src.offset((2) as isize)) as i32),
                    )) as u8);
                    *dest.offset((1) as isize) = ((*src.offset((3) as isize)) as u8);
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((4) as isize);
                    dest = dest.offset((2) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((4) * 8 + (3)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    *dest.offset((0) as isize) = ((*src.offset((0) as isize)) as u8);
                    *dest.offset((1) as isize) = ((*src.offset((1) as isize)) as u8);
                    *dest.offset((2) as isize) = ((*src.offset((2) as isize)) as u8);
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((4) as isize);
                    dest = dest.offset((3) as isize);
                }
            } else {
                c_runtime::free(data);
                c_runtime::free(good);
                return (((if (err("unsupported")) != 0 {
                    (0)
                } else {
                    (0)
                }) as u64) as *mut u8);
            }
        }
        c_runtime::pre_inc(&mut j);
    }
    c_runtime::free(data);
    return good;
}

pub unsafe fn convert_format16(
    mut data: *mut u16,
    mut img_n: i32,
    mut req_comp: i32,
    mut x: u32,
    mut y: u32,
) -> *mut u16 {
    let mut i: i32 = 0;
    let mut j: i32 = 0;
    let mut good: *mut u16 = core::ptr::null_mut();
    if req_comp == img_n {
        return data;
    }

    good = ((malloc(((((req_comp) as u32) * x * y * ((2) as u32)) as u64))) as *mut u16);
    if good == core::ptr::null_mut() {
        c_runtime::free(((data) as *mut u8));
        return ((((if (err("outofmem")) != 0 {
            (0)
        } else {
            (0)
        }) as u64) as *mut u8) as *mut u16);
    }
    j = ((0) as i32);
    while (j < ((y) as i32)) {
        let mut src: *mut u16 = (data).offset((((j) as u32) * x * ((img_n) as u32)) as isize);
        let mut dest: *mut u16 = (good).offset((((j) as u32) * x * ((req_comp) as u32)) as isize);
        {
            if ((img_n) * 8 + (req_comp)) == ((1) * 8 + (2)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    *dest.offset((0) as isize) = ((*src.offset((0) as isize)) as u16);
                    *dest.offset((1) as isize) = ((0xffff) as u16);
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((1) as isize);
                    dest = dest.offset((2) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((1) * 8 + (3)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    let hebron_tmp1 = *src.offset((0) as isize);
                    *dest.offset((0) as isize) = hebron_tmp1;
                    *dest.offset((1) as isize) = hebron_tmp1;
                    *dest.offset((2) as isize) = hebron_tmp1;
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((1) as isize);
                    dest = dest.offset((3) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((1) * 8 + (4)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    let hebron_tmp3 = *src.offset((0) as isize);
                    *dest.offset((0) as isize) = hebron_tmp3;
                    *dest.offset((1) as isize) = hebron_tmp3;
                    *dest.offset((2) as isize) = hebron_tmp3;
                    *dest.offset((3) as isize) = ((0xffff) as u16);
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((1) as isize);
                    dest = dest.offset((4) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((2) * 8 + (1)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    *dest.offset((0) as isize) = ((*src.offset((0) as isize)) as u16);
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((2) as isize);
                    dest = dest.offset((1) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((2) * 8 + (3)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    let hebron_tmp5 = *src.offset((0) as isize);
                    *dest.offset((0) as isize) = hebron_tmp5;
                    *dest.offset((1) as isize) = hebron_tmp5;
                    *dest.offset((2) as isize) = hebron_tmp5;
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((2) as isize);
                    dest = dest.offset((3) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((2) * 8 + (4)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    let hebron_tmp7 = *src.offset((0) as isize);
                    *dest.offset((0) as isize) = hebron_tmp7;
                    *dest.offset((1) as isize) = hebron_tmp7;
                    *dest.offset((2) as isize) = hebron_tmp7;
                    *dest.offset((3) as isize) = ((*src.offset((1) as isize)) as u16);
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((2) as isize);
                    dest = dest.offset((4) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((3) * 8 + (4)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    *dest.offset((0) as isize) = ((*src.offset((0) as isize)) as u16);
                    *dest.offset((1) as isize) = ((*src.offset((1) as isize)) as u16);
                    *dest.offset((2) as isize) = ((*src.offset((2) as isize)) as u16);
                    *dest.offset((3) as isize) = ((0xffff) as u16);
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((3) as isize);
                    dest = dest.offset((4) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((3) * 8 + (1)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    *dest.offset((0) as isize) = ((compute_y_16(
                        ((*src.offset((0) as isize)) as i32),
                        ((*src.offset((1) as isize)) as i32),
                        ((*src.offset((2) as isize)) as i32),
                    )) as u16);
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((3) as isize);
                    dest = dest.offset((1) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((3) * 8 + (2)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    *dest.offset((0) as isize) = ((compute_y_16(
                        ((*src.offset((0) as isize)) as i32),
                        ((*src.offset((1) as isize)) as i32),
                        ((*src.offset((2) as isize)) as i32),
                    )) as u16);
                    *dest.offset((1) as isize) = ((0xffff) as u16);
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((3) as isize);
                    dest = dest.offset((2) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((4) * 8 + (1)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    *dest.offset((0) as isize) = ((compute_y_16(
                        ((*src.offset((0) as isize)) as i32),
                        ((*src.offset((1) as isize)) as i32),
                        ((*src.offset((2) as isize)) as i32),
                    )) as u16);
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((4) as isize);
                    dest = dest.offset((1) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((4) * 8 + (2)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    *dest.offset((0) as isize) = ((compute_y_16(
                        ((*src.offset((0) as isize)) as i32),
                        ((*src.offset((1) as isize)) as i32),
                        ((*src.offset((2) as isize)) as i32),
                    )) as u16);
                    *dest.offset((1) as isize) = ((*src.offset((3) as isize)) as u16);
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((4) as isize);
                    dest = dest.offset((2) as isize);
                }
            } else if ((img_n) * 8 + (req_comp)) == ((4) * 8 + (3)) {
                i = ((x - ((1) as u32)) as i32);
                while (i >= 0) {
                    *dest.offset((0) as isize) = ((*src.offset((0) as isize)) as u16);
                    *dest.offset((1) as isize) = ((*src.offset((1) as isize)) as u16);
                    *dest.offset((2) as isize) = ((*src.offset((2) as isize)) as u16);
                    c_runtime::pre_dec(&mut i);
                    src = src.offset((4) as isize);
                    dest = dest.offset((3) as isize);
                }
            } else {
                c_runtime::free(((data) as *mut u8));
                c_runtime::free(((good) as *mut u8));
                return ((((if (err("unsupported")) != 0 {
                    (0)
                } else {
                    (0)
                }) as u64) as *mut u8) as *mut u16);
            }
        }
        c_runtime::pre_inc(&mut j);
    }
    c_runtime::free(((data) as *mut u8));
    return good;
}

pub unsafe fn get16be(mut s: *mut context) -> i32 {
    let mut z: i32 = ((get8(s)) as i32);
    return (z << 8) + ((get8(s)) as i32);
}

pub unsafe fn get16le(mut s: *mut context) -> i32 {
    let mut z: i32 = ((get8(s)) as i32);
    return z + (((get8(s)) as i32) << 8);
}

pub unsafe fn get32be(mut s: *mut context) -> u32 {
    let mut z: u32 = ((get16be(s)) as u32);
    return (z << 16) + ((get16be(s)) as u32);
}

pub unsafe fn get32le(mut s: *mut context) -> u32 {
    let mut z: u32 = ((get16le(s)) as u32);
    z += (((get16le(s)) as u32) << 16);
    return ((z) as u32);
}

pub unsafe fn get8(mut s: *mut context) -> u8 {
    if (*s).img_buffer < (*s).img_buffer_end {
        return ((*c_runtime::post_inc_const_ptr(&mut (*s).img_buffer)) as u8);
    }
    if ((*s).read_from_callbacks) != 0 {
        refill_buffer(s);
        return ((*c_runtime::post_inc_const_ptr(&mut (*s).img_buffer)) as u8);
    }
    return ((0) as u8);
}

pub unsafe fn getn(mut s: *mut context, mut buffer: *mut u8, mut n: i32) -> i32 {
    if ((*s).io.read) != core::ptr::null_mut() {
        let mut blen: i32 = ((((*s).img_buffer_end).offset(-(((*s).img_buffer) as isize))) as i32);
        if blen < n {
            let mut res: i32 = 0;
            let mut count: i32 = 0;
            c_runtime::memcpy(buffer, (*s).img_buffer, ((blen) as u64));
            count = (((*(*s).io.read)(
                (*s).io_user_data,
                ((buffer) as *mut i8).offset((blen) as isize),
                n - blen,
            )) as i32);
            res = ((if count == (n - blen) { 1 } else { 0 }) as i32);
            (*s).img_buffer = (*s).img_buffer_end;
            return ((res) as i32);
        }
    }
    if ((*s).img_buffer).offset((n) as isize) <= (*s).img_buffer_end {
        c_runtime::memcpy(buffer, (*s).img_buffer, ((n) as u64));
        (*s).img_buffer = (*s).img_buffer.offset((n) as isize);
        return ((1) as i32);
    } else {
        return ((0) as i32);
    }
}

pub unsafe fn high_bit(mut z: u32) -> i32 {
    let mut n: i32 = 0;
    if z == ((0) as u32) {
        return ((-1) as i32);
    }
    if z >= ((0x10000) as u32) {
        n += ((16) as i32);
        z >>= 16;
    }
    if z >= ((0x00100) as u32) {
        n += ((8) as i32);
        z >>= 8;
    }
    if z >= ((0x00010) as u32) {
        n += ((4) as i32);
        z >>= 4;
    }
    if z >= ((0x00004) as u32) {
        n += ((2) as i32);
        z >>= 2;
    }
    if z >= ((0x00002) as u32) {
        n += ((1) as i32);
    }
    return ((n) as i32);
}

pub unsafe fn info_main(
    mut s: *mut context,
    mut x: *mut i32,
    mut y: *mut i32,
    mut comp: *mut i32,
) -> i32 {
    if (png_info(s, x, y, comp)) != 0 {
        return ((1) as i32);
    }
    return ((err("unknown image type")) as i32);
}

pub unsafe fn is_16_main(mut s: *mut context) -> i32 {
    if (png_is16(s)) != 0 {
        return ((1) as i32);
    }
    return ((0) as i32);
}

pub unsafe fn ldr_to_hdr(
    mut data: *mut u8,
    mut x: i32,
    mut y: i32,
    mut comp: i32,
) -> *mut f32 {
    let mut i: i32 = 0;
    let mut k: i32 = 0;
    let mut n: i32 = 0;
    let mut output: *mut f32 = core::ptr::null_mut();
    if data == core::ptr::null_mut() {
        return core::ptr::null_mut();
    }
    output = ((malloc_mad4(x, y, comp, ((core::mem::size_of::<f32>() as u64) as i32), 0))
        as *mut f32);
    if output == core::ptr::null_mut() {
        c_runtime::free(data);
        return (((if (err("outofmem")) != 0 {
            (0)
        } else {
            (0)
        }) as u64) as *mut f32);
    }
    if (comp & 1) != 0 {
        n = ((comp) as i32);
    } else {
        n = ((comp - 1) as i32);
    }
    i = ((0) as i32);
    while (i < x * y) {
        k = ((0) as i32);
        while (k < n) {
            *output.offset((i * comp + k) as isize) = ((c_runtime::pow(
                (((((*data.offset((i * comp + k) as isize)) as i32) as f32) / 255.0f32) as f32),
                ((l2h_gamma) as f32),
            ) * ((l2h_scale) as f32))
                as f32);
            c_runtime::pre_inc(&mut k);
        }
        c_runtime::pre_inc(&mut i);
    }
    if n < comp {
        i = ((0) as i32);
        while (i < x * y) {
            *output.offset((i * comp + n) as isize) =
                ((((*data.offset((i * comp + n) as isize)) as i32) as f32) / 255.0f32);
            c_runtime::pre_inc(&mut i);
        }
    }
    c_runtime::free(data);
    return output;
}

pub unsafe fn load_and_postprocess_16bit(
    mut s: *mut context,
    mut x: *mut i32,
    mut y: *mut i32,
    mut comp: *mut i32,
    mut req_comp: i32,
) -> *mut u16 {
    let mut ri: result_info = result_info::default();
    let mut result: *mut u8 = load_main(
        s,
        x,
        y,
        comp,
        req_comp,
        ((&mut ri) as *mut result_info),
        16,
    );
    if result == core::ptr::null_mut() {
        return core::ptr::null_mut();
    }

    if ri.bits_per_channel != 16 {
        result = convert_8_to_16(
            ((result) as *mut u8),
            *x,
            *y,
            if req_comp == 0 { *comp } else { req_comp },
        ) as *mut u8;
        ri.bits_per_channel = ((16) as i32);
    }
    if (if (vertically_flip_on_load_set) != 0 {
        vertically_flip_on_load_local
    } else {
        vertically_flip_on_load_global
    }) != 0
    {
        let mut channels: i32 = if (req_comp) != 0 { req_comp } else { *comp };
        vertical_flip(
            result,
            *x,
            *y,
            ((((channels) as u64) * core::mem::size_of::<u16>() as u64) as i32),
        );
    }
    return ((result) as *mut u16);
}

pub unsafe fn load_and_postprocess_8bit(
    mut s: *mut context,
    mut x: *mut i32,
    mut y: *mut i32,
    mut comp: *mut i32,
    mut req_comp: i32,
) -> *mut u8 {
    let mut ri: result_info = result_info::default();
    let mut result: *mut u8 = load_main(
        s,
        x,
        y,
        comp,
        req_comp,
        ((&mut ri) as *mut result_info),
        8,
    );
    
    if result == core::ptr::null_mut() {
        return core::ptr::null_mut();
    }

    if ri.bits_per_channel != 8 {
        result = convert_16_to_8(
            (((result) as *mut u16) as *mut u16),
            *x,
            *y,
            if req_comp == 0 { *comp } else { req_comp },
        );
        ri.bits_per_channel = ((8) as i32);
    }
    if (if (vertically_flip_on_load_set) != 0 {
        vertically_flip_on_load_local
    } else {
        vertically_flip_on_load_global
    }) != 0
    {
        let mut channels: i32 = if (req_comp) != 0 { req_comp } else { *comp };
        vertical_flip(
            result,
            *x,
            *y,
            ((((channels) as u64) * core::mem::size_of::<u8>() as u64) as i32),
        );
    }
    return result;
}

pub unsafe fn load_main(
    mut s: *mut context,
    mut x: *mut i32,
    mut y: *mut i32,
    mut comp: *mut i32,
    mut req_comp: i32,
    mut ri: *mut result_info,
    mut bpc: i32,
) -> *mut u8 {
    c_runtime::memset(
        ((ri) as *mut u8),
        0,
        core::mem::size_of::<result_info>() as u64,
    );
    
    (*ri).bits_per_channel = ((8) as i32);
    (*ri).channel_order = ((STBI_ORDER_RGB) as i32);
    (*ri).num_channels = ((0) as i32);
    if (png_test(s)) != 0 {
      
        return png_load(s, x, y, comp, req_comp, ri);
    }
    return (((if (err("unknown image type")) != 0 {
        (0)
    } else {
        (0)
    }) as u64) as *mut u8);
}

pub unsafe fn loadf_main(
    mut s: *mut context,
    mut x: *mut i32,
    mut y: *mut i32,
    mut comp: *mut i32,
    mut req_comp: i32,
) -> *mut f32 {
    let mut data: *mut u8 = core::ptr::null_mut();
    data = load_and_postprocess_8bit(s, x, y, comp, req_comp);
    if (data) != core::ptr::null_mut() {
        return ldr_to_hdr(data, *x, *y, if (req_comp) != 0 { req_comp } else { *comp });
    }
    return (((if (err("unknown image type")) != 0 {
        (0)
    } else {
        (0)
    }) as u64) as *mut f32);
}

pub unsafe fn mad2sizes_valid(mut a: i32, mut b: i32, mut add: i32) -> i32 {
    return ((if (mul2sizes_valid(a, b)) != 0 && (addsizes_valid(a * b, add)) != 0 {
        1
    } else {
        0
    }) as i32);
}

pub unsafe fn mad3sizes_valid(mut a: i32, mut b: i32, mut c: i32, mut add: i32) -> i32 {
    return ((if (mul2sizes_valid(a, b)) != 0
        && (mul2sizes_valid(a * b, c)) != 0
        && (addsizes_valid(a * b * c, add)) != 0
    {
        1
    } else {
        0
    }) as i32);
}

pub unsafe fn mad4sizes_valid(
    mut a: i32,
    mut b: i32,
    mut c: i32,
    mut d: i32,
    mut add: i32,
) -> i32 {
    return ((if (mul2sizes_valid(a, b)) != 0
        && (mul2sizes_valid(a * b, c)) != 0
        && (mul2sizes_valid(a * b * c, d)) != 0
        && (addsizes_valid(a * b * c * d, add)) != 0
    {
        1
    } else {
        0
    }) as i32);
}

pub unsafe fn malloc(mut size: u64) -> *mut u8 {
    return c_runtime::malloc(size);
}

pub unsafe fn malloc_mad2(mut a: i32, mut b: i32, mut add: i32) -> *mut u8 {
    if mad2sizes_valid(a, b, add) == 0 {
        return core::ptr::null_mut();
    }
    return malloc(((a * b + add) as u64));
}

pub unsafe fn malloc_mad3(mut a: i32, mut b: i32, mut c: i32, mut add: i32) -> *mut u8 {
    if mad3sizes_valid(a, b, c, add) == 0 {
        return core::ptr::null_mut();
    }
    return malloc(((a * b * c + add) as u64));
}

pub unsafe fn malloc_mad4(
    mut a: i32,
    mut b: i32,
    mut c: i32,
    mut d: i32,
    mut add: i32,
) -> *mut u8 {
    if mad4sizes_valid(a, b, c, d, add) == 0 {
        return core::ptr::null_mut();
    }
    return malloc(((a * b * c * d + add) as u64));
}

pub unsafe fn mul2sizes_valid(mut a: i32, mut b: i32) -> i32 {
    if a < 0 || b < 0 {
        return ((0) as i32);
    }
    if b == 0 {
        return ((1) as i32);
    }
    return ((if a <= 2147483647 / b { 1 } else { 0 }) as i32);
}

pub unsafe fn paeth(mut a: i32, mut b: i32, mut c: i32) -> i32 {
    let mut p: i32 = a + b - c;
    let mut pa: i32 = c_runtime::abs(p - a);
    let mut pb: i32 = c_runtime::abs(p - b);
    let mut pc: i32 = c_runtime::abs(p - c);
    if pa <= pb && pa <= pc {
        return ((a) as i32);
    }
    if pb <= pc {
        return ((b) as i32);
    }
    return ((c) as i32);
}

pub unsafe fn refill_buffer(mut s: *mut context) {
    let mut n: i32 = (*(*s).io.read)(
        (*s).io_user_data,
        ((((*s).buffer_start.as_mut_ptr()) as *mut i8) as *mut i8),
        (*s).buflen,
    );
    (*s).callback_already_read +=
        ((((*s).img_buffer).offset(-(((*s).img_buffer_original) as isize))) as i32);
    if n == 0 {
        (*s).read_from_callbacks = ((0) as i32);
        (*s).img_buffer = (*s).buffer_start.as_mut_ptr();
        (*s).img_buffer_end = ((*s).buffer_start.as_mut_ptr()).offset((1) as isize);
        (*s).buffer_start[0] = 0;
    } else {
        (*s).img_buffer = (*s).buffer_start.as_mut_ptr();
        (*s).img_buffer_end = ((*s).buffer_start.as_mut_ptr()).offset((n) as isize);
    }
}

pub unsafe fn rewind(mut s: *mut context) {
    (*s).img_buffer = (*s).img_buffer_original;
    (*s).img_buffer_end = (*s).img_buffer_original_end;
}

pub unsafe fn shiftsigned(mut v: u32, mut shift: i32, mut bits: i32) -> i32 {
    if shift < 0 {
        v <<= -shift;
    } else {
        v >>= shift;
    }

    v >>= (8 - bits);

    return ((((v * shiftsigned_mul_table[(bits) as usize]) as i32)
        >> shiftsigned_shift_table[(bits) as usize]) as i32);
}

pub unsafe fn skip(mut s: *mut context, mut n: i32) {
    if n == 0 {
        return;
    }
    if n < 0 {
        (*s).img_buffer = (*s).img_buffer_end;
        return;
    }
    if ((*s).io.read) != core::ptr::null_mut() {
        let mut blen: i32 = ((((*s).img_buffer_end).offset(-(((*s).img_buffer) as isize))) as i32);
        if blen < n {
            (*s).img_buffer = (*s).img_buffer_end;
            (*(*s).io.skip)((*s).io_user_data, n - blen);
            return;
        }
    }
    (*s).img_buffer = (*s).img_buffer.offset((n) as isize);
}

pub unsafe fn start_callbacks(
    mut s: *mut context,
    mut c: *mut stbi_io_callbacks,
    mut user: *mut u8,
) {
    (*s).io = ((*c) as stbi_io_callbacks);
    (*s).io_user_data = user;
    (*s).buflen = ((128 * core::mem::size_of::<u8>() as u64) as i32);
    (*s).read_from_callbacks = ((1) as i32);
    (*s).callback_already_read = ((0) as i32);
    let hebron_tmp0 = (*s).buffer_start.as_mut_ptr();
    (*s).img_buffer = hebron_tmp0;
    (*s).img_buffer_original = hebron_tmp0;
    refill_buffer(s);
    (*s).img_buffer_original_end = (*s).img_buffer_end;
}

pub unsafe fn start_mem(mut s: *mut context, mut buffer: *const u8, mut len: i32) {
    (*s).io.read = core::ptr::null_mut();
    (*s).read_from_callbacks = ((0) as i32);
    (*s).callback_already_read = ((0) as i32);
    let hebron_tmp0 = buffer;
    (*s).img_buffer = hebron_tmp0;
    (*s).img_buffer_original = hebron_tmp0;
    let hebron_tmp1 = (buffer).offset((len) as isize);
    (*s).img_buffer_end = hebron_tmp1;
    (*s).img_buffer_original_end = hebron_tmp1;
}

pub unsafe fn unpremultiply_on_load_thread(mut flag_true_if_should_unpremultiply: i32) {
    unpremultiply_on_load_local = ((flag_true_if_should_unpremultiply) as i32);
    unpremultiply_on_load_set = ((1) as i32);
}

pub unsafe fn vertical_flip(
    mut image: *mut u8,
    mut w: i32,
    mut h: i32,
    mut bytes_per_pixel: i32,
) {
    let mut row: i32 = 0;
    let mut bytes_per_row: u64 = ((w) as u64) * ((bytes_per_pixel) as u64);
    let mut temp: [u8; 2048] = [0; 2048];
    let mut bytes: *mut u8 = image;
    row = ((0) as i32);
    while (row < (h >> 1)) {
        let mut row0: *mut u8 = (bytes).offset((((row) as u64) * bytes_per_row) as isize);
        let mut row1: *mut u8 = (bytes).offset((((h - row - 1) as u64) * bytes_per_row) as isize);
        let mut bytes_left: u64 = bytes_per_row;
        while ((bytes_left) != 0) {
            let mut bytes_copy: u64 = if (bytes_left < 2048 * core::mem::size_of::<u8>() as u64) {
                bytes_left
            } else {
                2048 * core::mem::size_of::<u8>() as u64
            };
            c_runtime::memcpy(((temp.as_mut_ptr()) as *mut u8), row0, bytes_copy);
            c_runtime::memcpy(row0, row1, bytes_copy);
            c_runtime::memcpy(row1, ((temp.as_mut_ptr()) as *mut u8), bytes_copy);
            row0 = row0.offset((bytes_copy) as isize);
            row1 = row1.offset((bytes_copy) as isize);
            bytes_left -= ((bytes_copy) as u64);
        }
        c_runtime::post_inc(&mut row);
    }
}

pub unsafe fn vertical_flip_slices(
    mut image: *mut u8,
    mut w: i32,
    mut h: i32,
    mut z: i32,
    mut bytes_per_pixel: i32,
) {
    let mut slice: i32 = 0;
    let mut slice_size: i32 = w * h * bytes_per_pixel;
    let mut bytes: *mut u8 = image;
    slice = ((0) as i32);
    while (slice < z) {
        vertical_flip(bytes, w, h, bytes_per_pixel);
        bytes = bytes.offset((slice_size) as isize);
        c_runtime::pre_inc(&mut slice);
    }
}

pub unsafe fn stbi_convert_iphone_png_to_rgb(mut flag_true_if_should_convert: i32) {
    de_iphone_flag_global = ((flag_true_if_should_convert) as i32);
}

pub unsafe fn stbi_convert_iphone_png_to_rgb_thread(mut flag_true_if_should_convert: i32) {
    de_iphone_flag_local = ((flag_true_if_should_convert) as i32);
    de_iphone_flag_set = ((1) as i32);
}

pub unsafe fn stbi_hdr_to_ldr_gamma(mut gamma: f32) {
    h2l_gamma_i = (((1) as f32) / gamma);
}

pub unsafe fn stbi_hdr_to_ldr_scale(mut scale: f32) {
    h2l_scale_i = (((1) as f32) / scale);
}

pub unsafe fn stbi_image_free(mut retval_from_stbi_load: *mut u8) {
    c_runtime::free(retval_from_stbi_load);
}

pub unsafe fn stbi_info_from_callbacks(
    mut c: *mut stbi_io_callbacks,
    mut user: *mut u8,
    mut x: *mut i32,
    mut y: *mut i32,
    mut comp: *mut i32,
) -> i32 {
    let mut s: context = context::default();
    start_callbacks(
        ((&mut s) as *mut context),
        ((c) as *mut stbi_io_callbacks),
        user,
    );
    return ((info_main(((&mut s) as *mut context), x, y, comp)) as i32);
}

pub unsafe fn stbi_info_from_memory(
    mut buffer: *const u8,
    mut len: i32,
    mut x: *mut i32,
    mut y: *mut i32,
    mut comp: *mut i32,
) -> i32 {
    let mut s: context = context::default();
    start_mem(((&mut s) as *mut context), buffer, len);
    return ((info_main(((&mut s) as *mut context), x, y, comp)) as i32);
}

pub unsafe fn stbi_is_16_bit_from_callbacks(
    mut c: *mut stbi_io_callbacks,
    mut user: *mut u8,
) -> i32 {
    let mut s: context = context::default();
    start_callbacks(
        ((&mut s) as *mut context),
        ((c) as *mut stbi_io_callbacks),
        user,
    );
    return ((is_16_main(((&mut s) as *mut context))) as i32);
}

pub unsafe fn stbi_is_16_bit_from_memory(mut buffer: *const u8, mut len: i32) -> i32 {
    let mut s: context = context::default();
    start_mem(((&mut s) as *mut context), buffer, len);
    return ((is_16_main(((&mut s) as *mut context))) as i32);
}

pub unsafe fn stbi_is_hdr_from_callbacks(
    mut clbk: *mut stbi_io_callbacks,
    mut user: *mut u8,
) -> i32 {
    return ((0) as i32);
}

pub unsafe fn stbi_is_hdr_from_memory(mut buffer: *const u8, mut len: i32) -> i32 {
    return ((0) as i32);
}

pub unsafe fn stbi_ldr_to_hdr_gamma(mut gamma: f32) {
    l2h_gamma = ((gamma) as f32);
}

pub unsafe fn stbi_ldr_to_hdr_scale(mut scale: f32) {
    l2h_scale = ((scale) as f32);
}

pub unsafe fn stbi_load_16_from_callbacks(
    mut clbk: *mut stbi_io_callbacks,
    mut user: *mut u8,
    mut x: *mut i32,
    mut y: *mut i32,
    mut channels_in_file: *mut i32,
    mut desired_channels: i32,
) -> *mut u16 {
    let mut s: context = context::default();
    start_callbacks(
        ((&mut s) as *mut context),
        ((clbk) as *mut stbi_io_callbacks),
        user,
    );
    return load_and_postprocess_16bit(
        ((&mut s) as *mut context),
        x,
        y,
        channels_in_file,
        desired_channels,
    );
}

pub unsafe fn stbi_load_16_from_memory(
    mut buffer: *const u8,
    mut len: i32,
    mut x: *mut i32,
    mut y: *mut i32,
    mut channels_in_file: *mut i32,
    mut desired_channels: i32,
) -> *mut u16 {
    let mut s: context = context::default();
    start_mem(((&mut s) as *mut context), buffer, len);
    return load_and_postprocess_16bit(
        ((&mut s) as *mut context),
        x,
        y,
        channels_in_file,
        desired_channels,
    );
}

pub unsafe fn stbi_load_from_callbacks(
    mut clbk: *mut stbi_io_callbacks,
    mut user: *mut u8,
    mut x: *mut i32,
    mut y: *mut i32,
    mut comp: *mut i32,
    mut req_comp: i32,
) -> *mut u8 {
    let mut s: context = context::default();
    start_callbacks(
        ((&mut s) as *mut context),
        ((clbk) as *mut stbi_io_callbacks),
        user,
    );
    return load_and_postprocess_8bit(((&mut s) as *mut context), x, y, comp, req_comp);
}

pub unsafe fn stbi_load_from_memory(
    mut buffer: *const u8,
    mut len: i32,
    mut x: *mut i32,
    mut y: *mut i32,
    mut comp: *mut i32,
    mut req_comp: i32,
) -> *mut u8 {
  
  
  let mut s: context = context::default();
  start_mem(((&mut s) as *mut context), buffer, len);
  return load_and_postprocess_8bit(((&mut s) as *mut context), x, y, comp, req_comp);
  
}

pub unsafe fn stbi_loadf_from_callbacks(
    mut clbk: *mut stbi_io_callbacks,
    mut user: *mut u8,
    mut x: *mut i32,
    mut y: *mut i32,
    mut comp: *mut i32,
    mut req_comp: i32,
) -> *mut f32 {
    let mut s: context = context::default();
    start_callbacks(
        ((&mut s) as *mut context),
        ((clbk) as *mut stbi_io_callbacks),
        user,
    );
    return loadf_main(((&mut s) as *mut context), x, y, comp, req_comp);
}

pub unsafe fn stbi_loadf_from_memory(
    mut buffer: *const u8,
    mut len: i32,
    mut x: *mut i32,
    mut y: *mut i32,
    mut comp: *mut i32,
    mut req_comp: i32,
) -> *mut f32 {
    let mut s: context = context::default();
    start_mem(((&mut s) as *mut context), buffer, len);
    return loadf_main(((&mut s) as *mut context), x, y, comp, req_comp);
}

pub unsafe fn stbi_set_flip_vertically_on_load(mut flag_true_if_should_flip: i32) {
    vertically_flip_on_load_global = ((flag_true_if_should_flip) as i32);
}

pub unsafe fn stbi_set_flip_vertically_on_load_thread(mut flag_true_if_should_flip: i32) {
    vertically_flip_on_load_local = ((flag_true_if_should_flip) as i32);
    vertically_flip_on_load_set = ((1) as i32);
}

pub unsafe fn stbi_set_unpremultiply_on_load(mut flag_true_if_should_unpremultiply: i32) {
    unpremultiply_on_load_global = ((flag_true_if_should_unpremultiply) as i32);
}